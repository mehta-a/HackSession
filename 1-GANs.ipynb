{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    " # Lab 1: Generative Adversarial Networks\n",
    "In this lab, we will explore several architectures of generative adversarial networks. There are many different versions of GANs existing today. The break-up for today's lab is as follows:<ol>\n",
    "1. Vanilla GAN\n",
    "2. Conditional GAN\n",
    "3. Cycle GAN\n",
    "\n",
    "These codes are modified from https://github.com/wiseodd/generative-models/tree/master/GAN\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Module 1: Vanilla GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Initialization of libraries\n",
    "import torch\n",
    "import torch.nn.functional as nn\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "device = torch.device('cuda')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining parameters for the training\n",
    "mb_size = 64 # Batch Size\n",
    "Z_dim = 100  # Length of noise vector\n",
    "X_dim = 784  # Input Length\n",
    "h_dim = 128  # Hidden Dimension\n",
    "lr = 1e-3    # Learning Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Custom weights initialization function.\n",
    "\n",
    "(Read later about Xavier initialization: http://andyljones.tumblr.com/post/110998971763/an-explanation-of-xavier-initialization)\n",
    "\n",
    "(Link to paper: https://arxiv.org/abs/1406.2661)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom weight initialization\n",
    "def xavier_init(size):\n",
    "    in_dim = size[0]\n",
    "    xavier_stddev = 1. / np.sqrt(in_dim / 2.)\n",
    "    vec = torch.randn(*size) * xavier_stddev\n",
    "\n",
    "    vec = vec.to(device)\n",
    "    vec.requires_grad = True\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We are using MNIST dataset for these experiments. Let us load the dataset. We will also define some functions that will be used for the other modules of this lab. Note that we are flattening the MNIST images into one dimensional vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "dataroot = './data'\n",
    "# Applying transformation to images\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0,), (1,))])\n",
    "\n",
    "# defining dataloader for the images\n",
    "trainset = torchvision.datasets.MNIST(root=dataroot , train=True, download=False,transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=mb_size, shuffle=True, num_workers=2)\n",
    "\n",
    "# function to get the next batch\n",
    "def mnist_next(dataiter):\n",
    "\n",
    "    try:\n",
    "        images, labels = dataiter.next()\n",
    "        images = images.view(images.numpy().shape[0],28*28)\n",
    "    except:\n",
    "        dataiter = iter(trainloader)\n",
    "        images, labels = dataiter.next()\n",
    "        images = images.view(images.numpy().shape[0],28*28)\n",
    "    return images.numpy(), labels\n",
    "\n",
    "# Initialization of dataloader\n",
    "def initialize_loader(trainset):\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=mb_size, shuffle=True, num_workers=2)\n",
    "    dataiter = iter(trainloader)\n",
    "    return dataiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "img = torchvision.utils.make_grid(images)\n",
    "npimg = img.numpy()\n",
    "plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " Now, let us define the network structure. For this experiment, we are not using deep networks. We are not even using torch.nn layers. Instead, we will use simple linear fully connected layers. The generator and discriminators are 2-layer networks. This is why we flattened the images in the block above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" ==================== GENERATOR ======================== \"\"\"\n",
    "# generator weight initialization\n",
    "Wzh = xavier_init(size=[Z_dim, h_dim])\n",
    "Whx = xavier_init(size=[h_dim, X_dim])\n",
    "\n",
    "# generator bias initialization\n",
    "bzvar = torch.zeros(h_dim);\n",
    "bhvar = torch.zeros(X_dim);\n",
    "\n",
    "bzvar = bzvar.to(device)\n",
    "bhvar = bhvar.to(device)\n",
    "    \n",
    "bzh = Variable(bzvar, requires_grad=True)\n",
    "bhx = Variable(bhvar, requires_grad=True)\n",
    "\n",
    "# trainable parameters of generator \n",
    "G_params = [Wzh, bzh, Whx, bhx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network architecture of generator\n",
    "def G(z):\n",
    "    h = nn.relu(torch.mm(z, Wzh) + bzh.repeat(z.size(0), 1))\n",
    "    X = nn.sigmoid(torch.mm(h, Whx) + bhx.repeat(h.size(0), 1))\n",
    "    return X  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" ==================== DISCRIMINATOR ======================== \"\"\"\n",
    "# Discriminator weight initialization\n",
    "Wxh = xavier_init(size=[X_dim, h_dim])\n",
    "Why = xavier_init(size=[h_dim, 1])\n",
    "\n",
    "# Discriminator bias initialization\n",
    "bxvar = torch.zeros(h_dim)\n",
    "bhvar = torch.zeros(1)\n",
    "\n",
    "bxvar = bxvar.to(device)\n",
    "bhvar = bhvar.to(device)\n",
    "    \n",
    "bxh = Variable(bxvar, requires_grad=True)\n",
    "bhy = Variable(bhvar, requires_grad=True)\n",
    "\n",
    "# trainable parameters of discriminator \n",
    "D_params = [Wxh, bxh, Why, bhy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network architecture of discriminator\n",
    "def D(X):\n",
    "    h = nn.relu(torch.mm(X, Wxh) + bxh.repeat(X.size(0), 1))\n",
    "    y = nn.sigmoid(torch.mm(h, Why) + bhy.repeat(h.size(0), 1))\n",
    "    return y  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Here, we will gather the parameters of the generator and the discriminator so that they can be given to the Adam optimizer to update the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "G_solver = optim.Adam(G_params, lr)\n",
    "D_solver = optim.Adam(D_params, lr)\n",
    "\n",
    "ones_label = torch.ones(mb_size,1)\n",
    "zeros_label = torch.zeros(mb_size,1)\n",
    "\n",
    "ones_label = ones_label.to(device)\n",
    "zeros_label = zeros_label.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the gradients to zero\n",
    "params = G_params + D_params\n",
    "def reset_grad():\n",
    "    for p in params:\n",
    "        p.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " Now, we will start the actual training. The training alternates between updating the discriminator network's weights and updating the generator's weight.First, we update the discriminator's weight. We take a minibatch from the dataset and do a forward pass on the discriminator with the label '1'. Then, we feed noise into the generator and feed the generated images into the discriminator with the label '0'. We backpropagate the error and update the discriminator weights. To update the generator weights, we feed noise to the generator and feed the generated images into the discriminator with the label '1'. This error is backpropagated to update the weights of G."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = initialize_loader(trainset)\n",
    "\n",
    "for it in range(10000):\n",
    "    \n",
    "    # Sample data\n",
    "    z = torch.randn(mb_size, Z_dim)\n",
    "    X, _ = mnist_next(dataiter)\n",
    "    if X.shape[0]!=mb_size:\n",
    "        dataiter = initialize_loader(trainset)\n",
    "        X,_ = mnist_next(dataiter)\n",
    "    X = torch.from_numpy(X)\n",
    "    \n",
    "    X = X.to(device)\n",
    "    z = z.to(device)\n",
    "    \n",
    "    # Dicriminator forward-loss-backward-update\n",
    "    \n",
    "    #forward pass\n",
    "    G_sample = G(z)\n",
    "    D_real = D(X)\n",
    "    D_fake = D(G_sample)\n",
    "    \n",
    "    # Calculate the loss\n",
    "    D_loss_real = nn.binary_cross_entropy(D_real, ones_label)\n",
    "    D_loss_fake = nn.binary_cross_entropy(D_fake, zeros_label)\n",
    "    D_loss = D_loss_real + D_loss_fake\n",
    "\n",
    "    # Calulate and update gradients of discriminator\n",
    "    D_loss.backward()\n",
    "    D_solver.step()\n",
    "\n",
    "    # reset gradient\n",
    "    reset_grad()\n",
    "\n",
    "    # Generator forward-loss-backward-update\n",
    "    \n",
    "    z = torch.randn(mb_size, Z_dim)\n",
    "    z = z.to(device)\n",
    "    G_sample = G(z)\n",
    "    D_fake = D(G_sample)\n",
    "\n",
    "    G_loss = nn.binary_cross_entropy(D_fake, ones_label)\n",
    "\n",
    "    G_loss.backward()\n",
    "    G_solver.step()\n",
    "\n",
    "    # reset gradient\n",
    "    reset_grad()\n",
    "\n",
    "    # Print and plot every now and then\n",
    "    if it % 1000 == 0:\n",
    "        print('Iter-{}; D_loss: {}; G_loss: {}'.format(it, D_loss.data.cpu().numpy(), G_loss.data.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Let us see the images generated by the generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.randn(mb_size, Z_dim)\n",
    "z = z.to(device)\n",
    "samples = G(z)\n",
    "samples = samples.cpu()\n",
    "img = samples.data\n",
    "img = img.view([64,1,28,28])\n",
    "img = torchvision.utils.make_grid(img)\n",
    "img = img.permute(1,2,0)\n",
    "plt.imshow(img.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image interpolation\n",
    "\n",
    "Let us try to interpolate between images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 64 random noise vector by interpolating between two noise vector\n",
    "a = torch.randn(Z_dim);\n",
    "b = torch.randn(Z_dim);\n",
    "noise = torch.Tensor(mb_size,Z_dim)\n",
    "line  = torch.linspace(0, 1, mb_size)\n",
    "for i in range(0, mb_size):\n",
    "    noise.select(0, i).copy_(a * line[i] + b * (1 - line[i]))\n",
    "noise = noise.to(device)\n",
    "\n",
    "# Feed forward the interpolated noise vector to generator\n",
    "samples = G(noise)\n",
    "samples = samples.cpu()\n",
    "\n",
    "# Plot the generated images\n",
    "img = samples.data\n",
    "img = img.view([mb_size,1,28,28])\n",
    "img = torchvision.utils.make_grid(img)\n",
    "img = img.permute(1,2,0)\n",
    "plt.imshow(img.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Points to ponder\n",
    "1. What happens if we don't do Xavier initialization?\n",
    "2. What happens if we change the learning rate and other parameters?\n",
    "3. What happens if we reduce the size of hidden layer to 10?\n",
    "4. Is there any way to determine the class of the generated images by changing the input noise vector?\n",
    "5. How long do we have to train the GAN to get good results? Can you plot the loss of the generator and discriminator and see if there is a correlation?\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
